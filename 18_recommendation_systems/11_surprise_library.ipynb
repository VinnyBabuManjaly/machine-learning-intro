{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5102c179",
   "metadata": {},
   "source": [
    "Here is a beginner‑friendly explanation of all the ideas, without any of the original examples.\n",
    "\n",
    "\n",
    "\n",
    "### What the SURPRISE library is\n",
    "\n",
    "SURPRISE is a Python library that helps you **build and evaluate recommender systems** that work with rating data (like “user rated item with 4 out of 5”). [nicolas-hug](https://nicolas-hug.com/project/surprise)\n",
    "\n",
    "Key points:\n",
    "\n",
    "- It is focused on **collaborative filtering**, where you use user–item ratings to predict new ratings. [pythonpodcast](https://www.pythonpodcast.com/episodepage/surprise-recommendation-algorithms-with-nicolas-hug)\n",
    "- Its design is similar in spirit to scikit‑learn: you create an algorithm object, you fit it on data, then you use it to predict. [surprise.readthedocs](https://surprise.readthedocs.io/en/stable/getting_started.html)\n",
    "- It includes many **rating prediction algorithms**: matrix factorization (SVD, NMF, SVD++), neighborhood methods (k‑nearest neighbors), and simple baseline methods. [nicolas-hug](https://nicolas-hug.com/project/surprise)\n",
    "- It also gives you **evaluation tools** like cross‑validation, train–test split, and error metrics (MSE, RMSE, MAE), plus tools for **hyperparameter tuning** such as grid search. [ejmste](https://www.ejmste.com/download/data-driven-recommendation-system-for-calculus-learning-using-funk-svd-evidence-from-a-mid-scale-16604.pdf)\n",
    "\n",
    "The main goal is to make it easy to try different recommender algorithms and measure how good their predictions are. [pythonpodcast](https://www.pythonpodcast.com/episodepage/surprise-recommendation-algorithms-with-nicolas-hug)\n",
    "\n",
    "\n",
    "\n",
    "### Data format and Dataset/Trainset/Testset\n",
    "\n",
    "#### Ratings as a list instead of a matrix\n",
    "\n",
    "In math, we often imagine ratings as a big **grid (matrix)**: rows are users, columns are items, entries are ratings. In practice, the data is usually stored as a **table with one row per rating**:\n",
    "\n",
    "- One column for user id  \n",
    "- One column for item id  \n",
    "- One column for the rating value  \n",
    "\n",
    "Pandas can store this as a DataFrame, but SURPRISE **does not work directly with pandas**; it expects its own internal dataset objects. [surprise.readthedocs](https://surprise.readthedocs.io/en/stable/FAQ.html)\n",
    "\n",
    "#### Reader and DatasetAutoFolds\n",
    "\n",
    "To convert a tabular ratings dataset into SURPRISE’s format you:\n",
    "\n",
    "- Create a **Reader** object, where you tell SURPRISE the **rating scale** (for example, ratings go from 0 to 5). [surprise.readthedocs](https://surprise.readthedocs.io/en/stable/getting_started.html)\n",
    "- Use `Dataset.load_from_df` (or other Dataset helpers) to wrap your table into a SURPRISE dataset object (one concrete implementation is `DatasetAutoFolds`). [surprise.readthedocs](https://surprise.readthedocs.io/en/stable/getting_started.html)\n",
    "\n",
    "This dataset object is a container that knows about all the ratings and their allowed range.\n",
    "\n",
    "#### Trainset vs testset (SURPRISE meaning)\n",
    "\n",
    "SURPRISE uses specific internal types:\n",
    "\n",
    "- A **Trainset** is an internal, encoded version of the ratings data used for training. It stores user and item ids as internal indices and includes all information the algorithm needs. [surprise.readthedocs](https://surprise.readthedocs.io/en/stable/FAQ.html)\n",
    "- A **testset** is just a **list of (user, item, true_rating)** triplets (plus possibly some extra fields) that you pass to an algorithm to get predictions back. [surprise.readthedocs](https://surprise.readthedocs.io/en/stable/FAQ.html)\n",
    "\n",
    "Important ideas:\n",
    "\n",
    "- To train on all available data, you call e.g. `data.build_full_trainset()`, which produces a Trainset. [surprise.readthedocs](https://surprise.readthedocs.io/en/stable/getting_started.html)\n",
    "- If you want to **evaluate on that same data**, SURPRISE gives a helper `trainset.build_testset()` that creates a testset that covers all known ratings in that Trainset. [surprise.readthedocs](https://surprise.readthedocs.io/en/stable/FAQ.html)\n",
    "- In a realistic workflow, you would **split** your data into training and test sets (or use cross‑validation) to avoid overfitting. [reintech](https://reintech.io/blog/how-to-create-a-recommendation-system-with-surprise)\n",
    "\n",
    "So the flow is:\n",
    "\n",
    "1. Dataset (high‑level container)  \n",
    "2. Build a Trainset (for training)  \n",
    "3. Build a testset (for evaluation)  \n",
    "\n",
    "\n",
    "\n",
    "### Algorithms: SVD / Funk SVD and others\n",
    "\n",
    "SURPRISE implements several **prediction algorithms**. [nicolas-hug](https://nicolas-hug.com/project/surprise)\n",
    "\n",
    "#### Funk SVD (matrix factorization idea)\n",
    "\n",
    "The SVD algorithm in SURPRISE is a **matrix factorization‑based recommender** related to what is often called “Funk SVD”. [github](https://github.com/gbolmier/funk-svd/blob/master/README.md)\n",
    "\n",
    "Conceptually:\n",
    "\n",
    "- Start with a big ratings matrix (users × items).  \n",
    "- Approximate it as the product of two **smaller matrices**:  \n",
    "  - A **user factor matrix** $P$: one row per user, each row is a vector of hidden “tastes”.  \n",
    "  - An **item factor matrix** $Q$: one row per item, each row is a vector of hidden “attributes”. [github](https://github.com/gbolmier/funk-svd/blob/master/README.md)\n",
    "- The predicted rating for a user–item pair is the **dot product** of that user’s factor vector and that item’s factor vector (possibly plus some biases). [github](https://github.com/gbolmier/funk-svd/blob/master/README.md)\n",
    "\n",
    "The number of hidden dimensions is called the number of **factors** (e.g., 2, 20, 50, etc.). [github](https://github.com/gbolmier/funk-svd/blob/master/README.md)\n",
    "Funk SVD learns these factors using **gradient descent**: it repeatedly adjusts the factors to make predicted ratings close to real ratings. [github](https://github.com/gbolmier/funk-svd/blob/master/README.md)\n",
    "\n",
    "This is **not** the same as the classic linear algebra singular value decomposition (even though the name sounds similar); it is an optimization‑based matrix factorization designed specifically for recommender systems. [github](https://github.com/gbolmier/funk-svd/blob/master/README.md)\n",
    "\n",
    "#### User and item factor matrices (pu and qi)\n",
    "\n",
    "In SURPRISE’s SVD implementation:\n",
    "\n",
    "- `model.pu` stores the **user latent factor matrix** (P). Each row corresponds to one user and contains that user’s hidden preference vector. [surprise.readthedocs](https://surprise.readthedocs.io/en/stable/getting_started.html)\n",
    "- `model.qi` stores the **item latent factor matrix** (Q). Each row corresponds to one item and contains that item’s hidden attribute vector. [surprise.readthedocs](https://surprise.readthedocs.io/en/stable/getting_started.html)\n",
    "\n",
    "Because training starts from random initial values and uses gradient descent, the specific numeric values you see in these matrices can change every time you re‑train, even on the same data. [github](https://github.com/gbolmier/funk-svd/blob/master/README.md)\n",
    "\n",
    "Interpreting factors:\n",
    "\n",
    "- Each factor (each column of these matrices) represents some **hidden dimension** of taste/content.  \n",
    "- Often, you can loosely interpret a factor (for example, “more like pop vs less like pop”), but sometimes factors do not have a clear human‑friendly meaning, and that is normal. [github](https://github.com/gbolmier/funk-svd/blob/master/README.md)\n",
    "\n",
    "#### Computing a single predicted rating\n",
    "\n",
    "To get one predicted rating for a user and an item when you think in terms of matrices:\n",
    "\n",
    "- Take the user’s factor vector from `pu`.  \n",
    "- Take the item’s factor vector from `qi`.  \n",
    "- Compute their **dot product**: multiply corresponding entries and add them up.  \n",
    "\n",
    "This gives the model’s estimate of how much that user would like that item. [github](https://github.com/gbolmier/funk-svd/blob/master/README.md)\n",
    "\n",
    "In matrix notation, if $P$ is users × factors and $Q$ is items × factors, the **full prediction matrix** (all users, all items) is $P \\times Q^\\top$, so matrix multiplication gives all predicted ratings at once. [github](https://github.com/gbolmier/funk-svd/blob/master/README.md)\n",
    "\n",
    "#### Other algorithms in SURPRISE\n",
    "\n",
    "SURPRISE also supports other techniques beyond this SVD‑style factorization: [reintech](https://reintech.io/blog/how-to-create-a-recommendation-system-with-surprise)\n",
    "\n",
    "- **SVD++**: a variant of SVD that also uses information about which items users have interacted with, not just their explicit ratings.  \n",
    "- **NMF** (Non‑negative Matrix Factorization): another factorization method where the learned factors are constrained to be non‑negative.  \n",
    "- **Neighborhood methods (k‑nearest neighbors)**: algorithms that use similarity between users or items; for example, predict a rating from ratings given by similar users or for similar items. [nicolas-hug](https://nicolas-hug.com/project/surprise)\n",
    "- Simple baseline and other algorithms bundled in `prediction_algorithms`.  \n",
    "\n",
    "You can experiment with different algorithms and compare their performance on the same dataset. [reintech](https://reintech.io/blog/how-to-create-a-recommendation-system-with-surprise)\n",
    "\n",
    "\n",
    "\n",
    "### Model training and hyperparameters\n",
    "\n",
    "#### Creating and training a model\n",
    "\n",
    "Using SURPRISE usually looks like this:\n",
    "\n",
    "1. Choose an algorithm class (for instance, `SVD`). [surprise.readthedocs](https://surprise.readthedocs.io/en/stable/getting_started.html)\n",
    "2. Create an object of that class, specifying **hyperparameters** such as:  \n",
    "   - `n_factors`: how many latent factors (size of the hidden vectors).  \n",
    "   - `n_epochs`: how many passes (epochs) over the data during training.  \n",
    "   - `biased`: whether to include global/user/item bias terms in the model.  \n",
    "3. Call `.fit(trainset)` with a Trainset object. You do **not** pass separate X and y arrays; the Trainset contains user ids, item ids, and ratings all together. [surprise.readthedocs](https://surprise.readthedocs.io/en/stable/getting_started.html)\n",
    "\n",
    "Because the Trainset stores everything in an internal format, SURPRISE just needs that one object to train the algorithm. [surprise.readthedocs](https://surprise.readthedocs.io/en/stable/FAQ.html)\n",
    "\n",
    "Hyperparameters:\n",
    "\n",
    "- A larger `n_factors` allows more expressive models, which can lower error on training data but increases risk of overfitting. [ejmste](https://www.ejmste.com/download/data-driven-recommendation-system-for-calculus-learning-using-funk-svd-evidence-from-a-mid-scale-16604.pdf)\n",
    "- `n_epochs` controls how long gradient descent runs; too few epochs can lead to underfitting, while too many can waste time or overfit. [ejmste](https://www.ejmste.com/download/data-driven-recommendation-system-for-calculus-learning-using-funk-svd-evidence-from-a-mid-scale-16604.pdf)\n",
    "- Turning off biases (`biased=False`) gives a “pure” matrix factorization that does not model per‑user or per‑item average shifts. [ejmste](https://www.ejmste.com/download/data-driven-recommendation-system-for-calculus-learning-using-funk-svd-evidence-from-a-mid-scale-16604.pdf)\n",
    "\n",
    "Choosing these values is part of **model selection**.\n",
    "\n",
    "\n",
    "\n",
    "### Making predictions\n",
    "\n",
    "SURPRISE provides two main ways to get predictions out of a trained model. [reintech](https://reintech.io/blog/how-to-create-a-recommendation-system-with-surprise)\n",
    "\n",
    "#### 1. `predict()` for a single user–item pair\n",
    "\n",
    "You can call:\n",
    "\n",
    "- `algo.predict(user_id, item_id)`\n",
    "\n",
    "This returns a **prediction object** that includes:\n",
    "\n",
    "- The user id  \n",
    "- The item id  \n",
    "- The **true rating** if known (for that pair in the dataset)  \n",
    "- The **estimated rating**  \n",
    "\n",
    "This method is for **one prediction at a time**. Unlike scikit‑learn, where `predict` usually takes a whole array, SURPRISE’s `predict` is single‑pair oriented. [reintech](https://reintech.io/blog/how-to-create-a-recommendation-system-with-surprise)\n",
    "\n",
    "You can use this to estimate ratings for:\n",
    "\n",
    "- Existing ratings (to see how close the model gets).  \n",
    "- New, unseen user–item pairs (to see what the model thinks the rating would be).\n",
    "\n",
    "#### 2. `test()` for a whole testset\n",
    "\n",
    "To evaluate many predictions at once:\n",
    "\n",
    "1. Create a **testset**: a list of (user, item, true_rating) triples. This can be from a held‑out test split or from `trainset.build_testset()` if you want to evaluate on the training data. [surprise.readthedocs](https://surprise.readthedocs.io/en/stable/FAQ.html)\n",
    "2. Call `algo.test(testset)`.  \n",
    "\n",
    "This returns a **list of prediction objects**, one per entry in the testset, each containing both the true and predicted rating. [reintech](https://reintech.io/blog/how-to-create-a-recommendation-system-with-surprise)\n",
    "\n",
    "The important design idea: SURPRISE **packages** true and predicted values into these prediction objects, instead of returning “plain” arrays.\n",
    "\n",
    "\n",
    "\n",
    "### Evaluating model error (MSE/RMSE) and overfitting\n",
    "\n",
    "#### Error metrics\n",
    "\n",
    "Once you have the list of prediction objects from `algo.test`, you can call functions from `surprise.accuracy` to compute metrics:\n",
    "\n",
    "- `accuracy.mse(predictions)` gives the **mean squared error** (average of squared differences between true and predicted ratings). [surprise.readthedocs](https://surprise.readthedocs.io/en/stable/FAQ.html)\n",
    "- `accuracy.rmse(predictions)` gives the **root mean squared error**. [reintech](https://reintech.io/blog/how-to-create-a-recommendation-system-with-surprise)\n",
    "\n",
    "These functions **do not** ask for separate arrays of y_true and y_pred; they read the true and estimated ratings from each prediction object. [surprise.readthedocs](https://surprise.readthedocs.io/en/stable/FAQ.html)\n",
    "\n",
    "A smaller MSE/RMSE means better prediction quality on that testset. [reintech](https://reintech.io/blog/how-to-create-a-recommendation-system-with-surprise)\n",
    "\n",
    "#### Overfitting and number of factors\n",
    "\n",
    "If you:\n",
    "\n",
    "- Use **many factors** or  \n",
    "- Train for **many epochs**  \n",
    "\n",
    "your model can become extremely good at fitting the training data (very low error on training testset), but may perform worse on new data (test or validation set). This is **overfitting**. [ejmste](https://www.ejmste.com/download/data-driven-recommendation-system-for-calculus-learning-using-funk-svd-evidence-from-a-mid-scale-16604.pdf)\n",
    "\n",
    "To handle this in SURPRISE, you:\n",
    "\n",
    "- Split your data into train and validation (or use k‑fold cross‑validation).  \n",
    "- Train models with different hyperparameter values (e.g., different `n_factors`).  \n",
    "- Pick the hyperparameters that perform best on validation error, not just training error. [surprise.readthedocs](https://surprise.readthedocs.io/en/stable/getting_started.html)\n",
    "\n",
    "SURPRISE includes tools like `train_test_split`, `KFold`, and `GridSearchCV` in `surprise.model_selection` to automate this procedure. [ejmste](https://www.ejmste.com/download/data-driven-recommendation-system-for-calculus-learning-using-funk-svd-evidence-from-a-mid-scale-16604.pdf)\n",
    "\n",
    "\n",
    "\n",
    "### Cross‑validation and Grid Search\n",
    "\n",
    "#### Cross‑validation\n",
    "\n",
    "**Cross‑validation** means you repeatedly split data into training and test parts in different ways, train on each training part, and average the performance over all splits. [reintech](https://reintech.io/blog/how-to-create-a-recommendation-system-with-surprise)\n",
    "\n",
    "SURPRISE provides:\n",
    "\n",
    "- `KFold` to run k‑fold cross‑validation loops manually.  \n",
    "- Convenience functions and examples to simplify this process. [surprise.readthedocs](https://surprise.readthedocs.io/en/stable/getting_started.html)\n",
    "\n",
    "You can use this to get a more stable estimate of your model’s performance.\n",
    "\n",
    "#### GridSearchCV\n",
    "\n",
    "`GridSearchCV` in SURPRISE lets you:\n",
    "\n",
    "- Specify a **grid of hyperparameter values** (for example, several choices for `n_factors`, `n_epochs`, learning rate, regularization strengths).  \n",
    "- Run cross‑validation for each combination.  \n",
    "- Automatically find the combination that gives the best metric (like lowest RMSE). [ejmste](https://www.ejmste.com/download/data-driven-recommendation-system-for-calculus-learning-using-funk-svd-evidence-from-a-mid-scale-16604.pdf)\n",
    "\n",
    "This helps you systematically tune your recommender without manually looping over parameter values.\n",
    "\n",
    "\n",
    "\n",
    "### High‑level philosophy of SURPRISE’s API\n",
    "\n",
    "Compared to scikit‑learn:\n",
    "\n",
    "- SURPRISE stores data in **annotated internal objects** (Dataset, Trainset, prediction objects) instead of raw arrays. [surprise.readthedocs](https://surprise.readthedocs.io/en/stable/FAQ.html)\n",
    "- Functions like `fit`, `test`, `predict`, `accuracy.mse` work with these objects, so they don’t always require separate X and y arguments. [surprise.readthedocs](https://surprise.readthedocs.io/en/stable/FAQ.html)\n",
    "\n",
    "In other words, SURPRISE tries to **bundle** related information together (user id, item id, true rating, predicted rating) and pass around these unified objects, making it convenient for recommender‑system‑specific workflows. [surprise.readthedocs](https://surprise.readthedocs.io/en/stable/FAQ.html)\n",
    "\n",
    "\n",
    "\n",
    "If you want, next step I can walk you through a minimal code template in plain English using SURPRISE for a small ratings dataset, focusing only on the concepts above."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
