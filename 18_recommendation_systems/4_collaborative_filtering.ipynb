{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81b3b5e5",
   "metadata": {},
   "source": [
    "**Collaborative filtering** solves the content-based filtering problem by starting with only incomplete user ratings data—no predefined item features or user preference surveys are needed. Instead, it learns both user factors and item factors automatically through an iterative process that improves predictions over repeated steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80a9e73",
   "metadata": {},
   "source": [
    "### Contrast with content-based filtering\n",
    "\n",
    "Content-based filtering requires **known item factors** (like genre tags or expert ratings) to infer user factors via linear regression per user. The \"reverse\" approach requires **known user factors** (like survey responses on music styles) to infer item factors via linear regression per item. Both need some upfront content metadata, which is hard to obtain at scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf303b4",
   "metadata": {},
   "source": [
    "### How collaborative filtering works\n",
    "\n",
    "**Core idea**: Treat both users and items symmetrically—learn latent factors for both simultaneously using only the ratings matrix.\n",
    "\n",
    "1. **Start with random item factors**  \n",
    "   - Assign each item $k$ random numeric factors (e.g., $k=2$: factor1, factor2).  \n",
    "   - These have no meaning—they're just starting points (e.g., Ommazh: [0.3, -0.7]).\n",
    "\n",
    "2. **Infer user factors (user regression step)**  \n",
    "   - For each user, fit linear regression: predict their known ratings using the current (random) item factors.  \n",
    "   - The learned regression coefficients become that user's factors (e.g., An: θ₁=-0.165, θ₂=3.98).  \n",
    "   - Prediction formula: rating = θ_user · factors_item (no intercept for simplicity).\n",
    "\n",
    "3. **Infer item factors (item regression step)**  \n",
    "   - For each item, fit linear regression: predict its known ratings using the current user factors.  \n",
    "   - The learned coefficients become that item's updated factors.\n",
    "\n",
    "4. **Repeat (alternating optimization)**  \n",
    "   - Use new item factors → infer new user factors → use new user factors → infer new item factors.  \n",
    "   - Each full cycle reduces squared error between predicted and actual ratings.  \n",
    "   - Stop when error converges or after fixed iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99653433",
   "metadata": {},
   "source": [
    "### Why this converges (no black magic)\n",
    "\n",
    "- It's **alternating least squares (ALS)** optimization of matrix factorization.  \n",
    "- Ratings matrix $R$ ≈ $U × V^T$, where $U$ = user factors matrix, $V$ = item factors matrix.  \n",
    "- Each step minimizes loss holding the other matrix fixed, like coordinate descent.  \n",
    "- The ratings data constrains the factors to make good predictions, so random starts evolve toward meaningful latent representations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187d1f99",
   "metadata": {},
   "source": [
    "### Key characteristics\n",
    "\n",
    "**Advantages over content-based**:\n",
    "- No manual feature engineering—factors emerge from data patterns.\n",
    "- Scales to millions of items/users without content metadata.\n",
    "- \"Collaborative\" because users' collective ratings reveal item similarities.\n",
    "\n",
    "**Properties of learned factors**:\n",
    "- Number of factors ($k$) is a hyperparameter (try 2, 10, 50+).\n",
    "- Factors are usually uninterpretable (not \"lo-fi indie,\" just abstract dimensions).\n",
    "- Handles sparse data naturally (missing ratings = no constraint).\n",
    "\n",
    "**Prediction for unseen items**:\n",
    "- Once converged: predicted_rating(user, item) = dot_product(user_factors, item_factors).\n",
    "- Rank items by predicted score to recommend top ones.\n",
    "\n",
    "This approach powers Netflix, Amazon, Spotify—any system with user-item interaction data but limited item metadata."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
