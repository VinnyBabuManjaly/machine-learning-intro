{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb551d9e",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "Classification is a supervised learning method where the goal is to predict *categories* (like “spam” vs “not spam”) using input features, and it is evaluated with metrics such as accuracy, precision, recall, F1 score, and ROC AUC rather than regression-style error measures like MSE. It sits alongside clustering, regression, and time series as one of the core problem types in machine learning, each with its own goals, data types, and typical algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08563e3",
   "metadata": {},
   "source": [
    "\n",
    "#### Big Picture: Four Core ML Problem Types\n",
    "\n",
    "Before zooming in on classification, it helps to see where it fits compared to clustering, regression, and time series, as in your transcript\n",
    "\n",
    "- **Regression (supervised)**  \n",
    "  - Predicts a *number* (continuous value).  \n",
    "  - Example: Predict house price from size, location, and number of rooms\n",
    "  - Typical metric: mean squared error (MSE), mean absolute error (MAE).  \n",
    "\n",
    "- **Classification (supervised)**  \n",
    "  - Predicts a *class label* (category).  \n",
    "  - Example: Email spam filter (spam vs not spam), churn prediction (will churn vs will not churn).\n",
    "  - Typical metrics: accuracy, precision, recall, F1 score, ROC AUC.\n",
    "\n",
    "- **Clustering (unsupervised)**  \n",
    "  - No labels; groups similar data points based on feature similarity. \n",
    "  - Example: Segment customers into groups based on behavior without predefined labels.\n",
    "  - Typical algorithm: k-means (you used this in Module 6).  \n",
    "\n",
    "- **Time Series (supervised or unsupervised)**  \n",
    "  - Data indexed by time; goal is usually *forecasting the future*.  \n",
    "  - Example: Forecast demand for the next month, predict stock prices, or detect seasonal patterns.\n",
    "  - Time (or lagged values) acts as a key input feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29afdf3d",
   "metadata": {},
   "source": [
    "#### Summary Table: Classification vs others\n",
    "\n",
    "| Aspect        | Classification                              | Clustering                                      | Regression                                  | Time Series                                        |\n",
    "|--------------|----------------------------------------------|-------------------------------------------------|---------------------------------------------|----------------------------------------------------|\n",
    "| Type         | Supervised learning                          | Unsupervised learning                           | Supervised learning                         | Supervised or unsupervised                         |\n",
    "| Output       | Category/label (discrete)                    | Group/cluster IDs (discovered, not given)       | Continuous value (number)                   | Usually continuous forecast over time              |\n",
    "| Goal         | Assign data to classes                       | Group similar points                            | Predict numeric outcomes                    | Forecast future values or detect temporal patterns |\n",
    "| Example      | Spam detection, churn prediction             | Customer segments, pattern discovery            | House price prediction                      | Sales forecast, weather forecast                   |\n",
    "| Typical alg. | k-NN, decision trees, logistic regression    | k-means                                         | Linear regression, ridge, lasso             | ARMA/ARIMA, time-series regression                 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b21816d",
   "metadata": {},
   "source": [
    "#### What Classification Really Does\n",
    "\n",
    "At a high level, a classification model learns a rule that maps input features to a class label.\n",
    "\n",
    "- **Inputs (features / predictors)**  \n",
    "  - Example: For spam detection, features can include word frequencies, presence of links, sender address pattern, etc.\n",
    "\n",
    "- **Output (target / label)**  \n",
    "  - Example: `spam` or `not spam`; `churn` or `no churn`; `0` or `1` for binary classification.\n",
    "\n",
    "- **Supervised part**  \n",
    "  - During training, the model sees examples *with known labels*, so it learns how feature patterns relate to classes.\n",
    "\n",
    "- **Prediction**  \n",
    "  - For a new, unseen example, the model outputs:\n",
    "    - A **class** (hard prediction), and often\n",
    "    - A **probability** for each class (e.g., 0.9 spam, 0.1 not spam).\n",
    "\n",
    "If the target is a category, it is a classification problem; if the target is numeric (like price), it is regression. The transcript’s example of housing prices is regression; switching to “high price vs low price” turns it into classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044d8756",
   "metadata": {},
   "source": [
    "#### Classification vs Regression (Deeper Intuition)\n",
    "\n",
    "Your transcript already highlights the key distinction: classification predicts *categorical labels*, regression predicts *continuous numbers*.\n",
    "\n",
    "- If the output space is **finite and discrete** (e.g., 0/1, A/B/C), it is classification.  \n",
    "- If the output can take **any real value** over a range (e.g., 250000.45), it is regression.  \n",
    "\n",
    "This difference affects:\n",
    "\n",
    "- **Model choice**  \n",
    "  - Logistic regression, decision trees, k-NN, SVMs for classification.  \n",
    "  - Linear regression, ridge, lasso, and others for regression.\n",
    "- **Evaluation metrics**  \n",
    "  - Regression: MSE, MAE, \\(R^2\\), etc.  \n",
    "  - Classification: accuracy, precision, recall, F1, ROC AUC.\n",
    "\n",
    "Even if the underlying model is similar (e.g., linear regression vs logistic regression), the loss function and interpretation differ because one predicts numbers and the other predicts probabilities and classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b121d3",
   "metadata": {},
   "source": [
    "#### Python-Level View (High-Level, No Code Needed)\n",
    "\n",
    "In typical scikit-learn workflows for classification:\n",
    "\n",
    "- **Training a classifier**  \n",
    "  - Choose an algorithm (e.g., `KNeighborsClassifier`, `DecisionTreeClassifier`).  \n",
    "  - Fit it on `X_train` (features) and `y_train` (class labels).  \n",
    "\n",
    "- **Making predictions**  \n",
    "  - Use `.predict(X_test)` for predicted classes.  \n",
    "  - Use `.predict_proba(X_test)` (if available) for class probabilities (needed for ROC and AUC).\n",
    "\n",
    "- **Evaluating the model**  \n",
    "  - Use functions from `sklearn.metrics`, such as:\n",
    "    - `accuracy_score`, `precision_score`, `recall_score`, `f1_score`, `roc_curve`, `auc`, or `roc_auc_score`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfef6978",
   "metadata": {},
   "source": [
    "Sources: \n",
    "\n",
    "[1](https://www.geeksforgeeks.org/machine-learning/sklearn-classification-metrics/)\n",
    "[2](https://www.youtube.com/watch?v=LsRhnsmcSJU)\n",
    "[3](https://developers.google.com/machine-learning/crash-course/classification/accuracy-precision-recall)\n",
    "[4](https://www.sktime.net/en/stable/examples/02_classification.html)\n",
    "[5](https://www.appliedaicourse.com/blog/knn-algorithm-in-machine-learning/)\n",
    "[6](https://www.geeksforgeeks.org/machine-learning/metrics-for-machine-learning-model/)\n",
    "[7](https://www.perplexity.ai/search/b9562bc2-0f36-4a06-bd85-47347418e740)\n",
    "[8](https://ocw.mit.edu/courses/6-034-artificial-intelligence-fall-2010/4efa5e563ccb9d54fdd72068a8dda879_MIT6_034F10_tutor03.pdf)\n",
    "[9](https://pages.mtu.edu/~shanem/psy5220/daily/Day13/treesforestsKNN.html)\n",
    "[10](https://www.geeksforgeeks.org/machine-learning/evaluation-metrics-for-classification-model-in-python/)\n",
    "[11](https://filippomb.github.io/python-time-series-handbook/notebooks/12/classification-clustering.html)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
