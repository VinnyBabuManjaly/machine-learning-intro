{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64b348e1",
   "metadata": {},
   "source": [
    "\n",
    "### How Neural Networks Process Data\n",
    "\n",
    "A neural network takes inputs and passes them through **layers of neurons**:\n",
    "\n",
    "1. **Each neuron** computes a **weighted sum** of its inputs + **bias**.  \n",
    "2. An **activation function** (like sigmoid) transforms this sum into the neuron’s output.  \n",
    "3. These outputs become inputs to the **next layer**.\n",
    "\n",
    "**Key Insight:** Each layer creates **new features** — abstract representations that are more useful than the original inputs.\n",
    "\n",
    "\n",
    "\n",
    "### Multi‑Layer Structure\n",
    "\n",
    "```\n",
    "Input Layer → Hidden Layer 1 → Hidden Layer 2 → ... → Output Layer\n",
    "```\n",
    "\n",
    "- **Hidden layers** generate increasingly complex features.  \n",
    "- **Output layer** uses final features to make predictions.\n",
    "\n",
    "\n",
    "\n",
    "### Automatic Feature Discovery\n",
    "\n",
    "Neural networks **automatically learn useful features** through training:\n",
    "- Early layers might detect simple patterns.  \n",
    "- Later layers combine them into complex, powerful representations.  \n",
    "- You don’t need to manually invent good features — the network discovers them.\n",
    "\n",
    "\n",
    "\n",
    "### Activation Functions Matter\n",
    "\n",
    "Different activations enable different behaviors:\n",
    "- **Sigmoid:** Smooth on/off switch (can be slow for deep networks).  \n",
    "- **Tanh/ReLU:** Better for deeper networks, enable complex patterns.\n",
    "\n",
    "\n",
    "\n",
    "### Training Behavior\n",
    "\n",
    "- **Shallow networks** (no hidden layers) = simple decision boundaries.  \n",
    "- **Deeper networks** = more complex boundaries.  \n",
    "- Each training run may produce **slightly different results** due to gradient descent randomness.\n",
    "\n",
    "\n",
    "\n",
    "**Core Power:**  \n",
    "Neural networks **automatically transform raw data into optimal features** layer by layer — this is why they excel where traditional methods fail.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
