{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b01d0f4",
   "metadata": {},
   "source": [
    "### Step 1: The 2D linear regression model and per‑point loss\n",
    "\n",
    "We work with a **two‑dimensional** linear regression model with no explicit intercept term: the input has two features $x_0$ and $x_1$, and the model has two parameters $\\theta_0$ and $\\theta_1$. [mattsosna](https://mattsosna.com/LR-grad-desc/)\n",
    "\n",
    "- Model prediction for a single data point $i$:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = \\theta_0 x_{0,i} + \\theta_1 x_{1,i}\n",
    "$$\n",
    "\n",
    "- Squared error loss **for that single point**:\n",
    "\n",
    "$$\n",
    "\\ell_i(\\theta_0,\\theta_1) = (y_i - \\hat{y}_i)^2\n",
    "= \\big(y_i - \\theta_0 x_{0,i} - \\theta_1 x_{1,i}\\big)^2\n",
    "$$\n",
    "\n",
    "Here:\n",
    "\n",
    "- $y_i$: true target for point i  \n",
    "- $x_{0,i}, x_{1,i}$: the two feature values for point i  \n",
    "- $\\theta_0, \\theta_1$: model parameters we want to learn  \n",
    "\n",
    "This is **per‑example loss**, not averaged yet over all points. [mattsosna](https://mattsosna.com/LR-grad-desc/)\n",
    "\n",
    "In the tips example:\n",
    "\n",
    "- $x_0$ is a **bias** feature (all ones), representing the fixed offset tip. [pyimagesearch](https://pyimagesearch.com/2016/10/10/gradient-descent-with-python/)\n",
    "- $x_1$ is the **bill amount**. [pyimagesearch](https://pyimagesearch.com/2016/10/10/gradient-descent-with-python/)\n",
    "\n",
    "So the prediction is effectively:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = \\theta_0 \\cdot 1 + \\theta_1 \\cdot \\text{bill}_i\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518efe1f",
   "metadata": {},
   "source": [
    "### Step 2: Gradient of the loss for one data point\n",
    "\n",
    "The gradient has two components:\n",
    "\n",
    "$$\n",
    "\\nabla_{\\theta} \\ell_i =\n",
    "\\begin{bmatrix}\n",
    "\\dfrac{\\partial \\ell_i}{\\partial \\theta_0} \\\\\n",
    "\\dfrac{\\partial \\ell_i}{\\partial \\theta_1}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Let\n",
    "\n",
    "$$\n",
    "e_i = y_i - \\theta_0 x_{0,i} - \\theta_1 x_{1,i}\n",
    "$$\n",
    "\n",
    "Then\n",
    "\n",
    "$$\n",
    "\\ell_i = e_i^2\n",
    "$$\n",
    "\n",
    "Use the chain rule:\n",
    "\n",
    "1. $\\dfrac{\\partial \\ell_i}{\\partial e_i} = 2 e_i$  \n",
    "2. $\\dfrac{\\partial e_i}{\\partial \\theta_0} = -x_{0,i}$  \n",
    "3. $\\dfrac{\\partial e_i}{\\partial \\theta_1} = -x_{1,i}$\n",
    "\n",
    "So:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\ell_i}{\\partial \\theta_0}\n",
    "= 2 e_i \\cdot (-x_{0,i})\n",
    "= -2\\, (y_i - \\theta_0 x_{0,i} - \\theta_1 x_{1,i})\\, x_{0,i}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\ell_i}{\\partial \\theta_1}\n",
    "= 2 e_i \\cdot (-x_{1,i})\n",
    "= -2\\, (y_i - \\theta_0 x_{0,i} - \\theta_1 x_{1,i})\\, x_{1,i}\n",
    "$$\n",
    "\n",
    "The above can be written as:\n",
    "\n",
    "- $2(y_i - \\theta_0 x_0 - \\theta_1 x_1)(-x_0)$ for the θ₀ component  \n",
    "- $2(y_i - \\theta_0 x_0 - \\theta_1 x_1)(-x_1)$ for the θ₁ component  \n",
    "\n",
    "and notes the minus $x_0$ or minus $x_1$ comes from the chain rule. [mattsosna](https://mattsosna.com/LR-grad-desc/)\n",
    "\n",
    "In column‑vector form:\n",
    "\n",
    "$$\n",
    "\\nabla_{\\theta} \\ell_i =\n",
    "\\begin{bmatrix}\n",
    "-2\\, (y_i - \\theta_0 x_{0,i} - \\theta_1 x_{1,i})\\, x_{0,i} \\\\\n",
    "-2\\, (y_i - \\theta_0 x_{0,i} - \\theta_1 x_{1,i})\\, x_{1,i}\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6441f60",
   "metadata": {},
   "source": [
    "### Step 3: Average gradient over all data points\n",
    "\n",
    "The model loss over the **whole dataset** is the average of per‑point losses:\n",
    "\n",
    "$$\n",
    "L(\\theta_0,\\theta_1)\n",
    "= \\frac{1}{n} \\sum_{i=1}^n \\ell_i(\\theta_0,\\theta_1)\n",
    "$$\n",
    "\n",
    "So the gradient of the overall loss is the average of the per‑point gradients:\n",
    "\n",
    "$$\n",
    "\\nabla_{\\theta} L\n",
    "= \\frac{1}{n} \\sum_{i=1}^n \\nabla_{\\theta} \\ell_i\n",
    "$$\n",
    "\n",
    "Component‑wise:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\theta_0}\n",
    "= \\frac{1}{n}\\sum_{i=1}^n -2\\, (y_i - \\theta_0 x_{0,i} - \\theta_1 x_{1,i})\\, x_{0,i}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\theta_1}\n",
    "= \\frac{1}{n}\\sum_{i=1}^n -2\\, (y_i - \\theta_0 x_{0,i} - \\theta_1 x_{1,i})\\, x_{1,i}\n",
    "$$\n",
    "\n",
    "Instead of summing over all data points only, you should average them. [mattsosna](https://mattsosna.com/LR-grad-desc/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155f7d61",
   "metadata": {},
   "source": [
    "### Step 4: Writing the gradient in Python \n",
    "The code mirrors the formulas directly, with:\n",
    "\n",
    "- `x0` = first column of `X` (bias = ones)  \n",
    "- `x1` = second column of `X` (bill)  \n",
    "- `theta[0]` = $\\theta_0$, `theta[1]` = $\\theta_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8732eee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Loading tips dataset\n",
    "df = sns.load_dataset(\"tips\")\n",
    "\n",
    "# Add bias column\n",
    "df[\"bias\"] = 1.0\n",
    "\n",
    "# Feature matrix X and target y\n",
    "X = df[[\"bias\", \"total_bill\"]]  \n",
    "y = df[\"tip\"]            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7c8a67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_gradient(theta, X, y_obs):\n",
    "    \"\"\"Returns the gradient of the MSE on our data for the given theta\"\"\"    \n",
    "    x0 = X.iloc[:, 0]\n",
    "    x1 = X.iloc[:, 1]\n",
    "    dth0 = np.mean(-2 * (y_obs - theta[0]*x0 - theta[1]*x1) * x0)\n",
    "    dth1 = np.mean(-2 * (y_obs - theta[0]*x0 - theta[1]*x1) * x1)\n",
    "    return np.array([dth0, dth1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b5a8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  -5.99655738 -135.22631803]\n"
     ]
    }
   ],
   "source": [
    "theta_init = np.array([0.0, 0.0])\n",
    "grad_at_zero = mse_gradient(np.array([0, 0]), X, y)\n",
    "print(grad_at_zero)\n",
    "\n",
    "# both are negative, meaning **increase** both θ₀ and θ₁ to reduce loss (since gradient descent updates subtract the gradient). \n",
    "# [stackoverflow](https://stackoverflow.com/questions/17784587/gradient-descent-using-python-and-numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edae6c3",
   "metadata": {},
   "source": [
    "### Step 5: Single‑argument gradient wrapper\n",
    "\n",
    "As with the loss, it is convenient to create a **single‑argument** gradient function that only takes θ; X and y are captured from the outer scope:\n",
    "\n",
    "```python\n",
    "def gradient_single_arg(theta):\n",
    "    return gradient_theta(X, y, theta)\n",
    "```\n",
    "\n",
    "Now you can evaluate the “2D slope” at any θ by calling:\n",
    "\n",
    "```python\n",
    "gradient_single_arg(np.array([0.0, 0.0]))\n",
    "# -> large magnitude entries (far from optimum)\n",
    "\n",
    "gradient_single_arg(np.array([0.9, 0.1]))\n",
    "# -> much smaller gradient (close to optimum)\n",
    "```\n",
    "\n",
    "The transcript notes that for θ close to the correct answer (~0.9, 0.1), the gradient components are **small**, indicating you are near a minimum. [stackoverflow](https://stackoverflow.com/questions/17784587/gradient-descent-using-python-and-numpy)\n",
    "\n",
    "***\n",
    "\n",
    "### Step 6: Reusing the same gradient descent function (1D → 2D)\n",
    "\n",
    "A crucial point in the transcript: the **same** generic gradient‑descent function used in 1D works unchanged in 2D, thanks to NumPy’s vectorization. [stackoverflow](https://stackoverflow.com/questions/17784587/gradient-descent-using-python-and-numpy)\n",
    "\n",
    "A generic gradient descent:\n",
    "\n",
    "```python\n",
    "def gradient_descent(df, theta_init, alpha, n_steps):\n",
    "    \"\"\"\n",
    "    df:  function that returns gradient given theta (shape (d,))\n",
    "    theta_init: initial parameter vector\n",
    "    alpha: learning rate\n",
    "    n_steps: number of iterations\n",
    "    \"\"\"\n",
    "    theta = theta_init.copy()\n",
    "    for step in range(n_steps):\n",
    "        grad = df(theta)          # df returns vector gradient\n",
    "        theta = theta - alpha * grad\n",
    "    return theta\n",
    "```\n",
    "\n",
    "Note:\n",
    "\n",
    "- In 1D, `theta` was a scalar, `grad` was a scalar; subtraction worked.  \n",
    "- In 2D, `theta` is a 2‑element NumPy array, `grad` is a 2‑element array; subtraction also works elementwise.  \n",
    "\n",
    "So we simply pass the new 2D gradient:\n",
    "\n",
    "```python\n",
    "theta_start = np.array([0.0, 0.0])\n",
    "alpha = 0.0001            # example learning rate\n",
    "n_steps = 100000          # many steps (the transcript notes this is slow)\n",
    "\n",
    "theta_gd = gradient_descent(gradient_single_arg, theta_start, alpha, n_steps)\n",
    "print(theta_gd)\n",
    "```\n",
    "\n",
    "- The instructor mentions not actually running it live because it takes ~30s–1min as written. [stackoverflow](https://stackoverflow.com/questions/17784587/gradient-descent-using-python-and-numpy)\n",
    "- After running, the trajectory moves from (0, 0) toward something like (0.888, 0.10), close to the optimal (0.92, 0.105). [towardsdatascience](https://towardsdatascience.com/linear-regression-and-gradient-descent-for-absolute-beginners-eef9574eadb0/)\n",
    "\n",
    "You can track the path by recording θ at each step:\n",
    "\n",
    "```python\n",
    "def gradient_descent_with_trace(df, theta_init, alpha, n_steps):\n",
    "    theta = theta_init.copy()\n",
    "    trace = [theta.copy()]\n",
    "    for step in range(n_steps):\n",
    "        grad = df(theta)\n",
    "        theta = theta - alpha * grad\n",
    "        trace.append(theta.copy())\n",
    "    return theta, np.array(trace)\n",
    "```\n",
    "\n",
    "This trace can be plotted over the 2D loss surface (contours) to visualize the “path” sliding down toward the minimum; the transcript says you will explore such visualization on homework. [mattsosna](https://mattsosna.com/LR-grad-desc/)\n",
    "\n",
    "***\n",
    "\n",
    "### Step 7: Behavior of gradient descent in 2D\n",
    "\n",
    "The transcript notes several qualitative behaviors:\n",
    "\n",
    "- Starting from θ = , both components of the gradient are negative, so the algorithm increases both θ₀ and θ₁. [stackoverflow](https://stackoverflow.com/questions/17784587/gradient-descent-using-python-and-numpy)\n",
    "- Early steps: the parameters move **quickly**, making large jumps as gradients are large. [towardsdatascience](https://towardsdatascience.com/linear-regression-and-gradient-descent-for-absolute-beginners-eef9574eadb0/)\n",
    "- As we approach the bottom of the “bowl” (the convex loss surface), gradients shrink, steps become small, and θ values approach the optimal solution. [towardsdatascience](https://towardsdatascience.com/linear-regression-and-gradient-descent-for-absolute-beginners-eef9574eadb0/)\n",
    "- With the simple implementation and chosen learning rate, the algorithm gets to about (0.888, 0.10), close but not exactly the scikit‑learn optimum, because:\n",
    "  - learning rate may be suboptimal  \n",
    "  - fixed step size  \n",
    "  - limited iterations  \n",
    "\n",
    "The instructor comments that this simple implementation is **“finicky”**: different starting points or learning rates can change convergence speed and behavior. Industrial‑strength implementations need more robust strategies (e.g., adaptive step sizes, momentum, etc.). [stackabuse](https://stackabuse.com/gradient-descent-in-python-implementation-and-theory/)\n",
    "\n",
    "***\n",
    "\n",
    "### Step 8: Big picture and why this is “cool”\n",
    "\n",
    "The transcript’s main takeaways:\n",
    "\n",
    "- You derive the gradient of the **per‑example squared error** for the 2D linear regression model using calculus and chain rule. [youtube](https://www.youtube.com/watch?v=KLXP2RL0-Vg)\n",
    "- You average across all data to get the gradient of the overall loss. [mattsosna](https://mattsosna.com/LR-grad-desc/)\n",
    "- You implement that gradient directly in Python/NumPy and plug it into a **generic** gradient descent routine previously used for 1D. [stackoverflow](https://stackoverflow.com/questions/17784587/gradient-descent-using-python-and-numpy)\n",
    "- Without relying on scikit‑learn or other libraries’ optimizers, you now numerically find near‑optimal values for both θ₀ and θ₁ for the tips dataset. [mattsosna](https://mattsosna.com/LR-grad-desc/)\n",
    "\n",
    "You’ve effectively built your own small 2D gradient descent optimizer for linear regression from first principles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c24f84d",
   "metadata": {},
   "source": [
    "\n",
    "A faithful Python version:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def gradient_theta(X, y_obs, theta):\n",
    "    \"\"\"\n",
    "    X: shape (n_samples, 2) -> columns: x0 (bias), x1 (bill)\n",
    "    y_obs: shape (n_samples,)\n",
    "    theta: shape (2,) -> [theta0, theta1]\n",
    "    \"\"\"\n",
    "    x0 = X[:, 0]  # all ones (bias)\n",
    "    x1 = X[:, 1]  # bill\n",
    "\n",
    "    theta0, theta1 = theta\n",
    "\n",
    "    # prediction: theta0 * x0 + theta1 * x1\n",
    "    y_pred = theta0 * x0 + theta1 * x1\n",
    "    residual = y_obs - y_pred  # y_i - (theta0*x0 + theta1*x1)\n",
    "\n",
    "    # components of gradient (note the minus sign)\n",
    "    d_theta0 = -2 * residual * x0\n",
    "    d_theta1 = -2 * residual * x1\n",
    "\n",
    "    # average across all points (np.mean is what transcript fixes)\n",
    "    grad_theta0 = np.mean(d_theta0)\n",
    "    grad_theta1 = np.mean(d_theta1)\n",
    "\n",
    "    return np.array([grad_theta0, grad_theta1])\n",
    "```\n",
    "\n",
    "- Initially, the instructor forgets to take the mean and then fixes it with `np.mean`. [mattsosna](https://mattsosna.com/LR-grad-desc/)\n",
    "- The returned gradient has two components, for θ₀ and θ₁.\n",
    "\n",
    "If you call:\n",
    "\n",
    "```python\n",
    "theta_init = np.array([0.0, 0.0])\n",
    "grad_at_zero = gradient_theta(X, y, theta_init)\n",
    "print(grad_at_zero)\n",
    "```\n",
    "\n",
    "You get something like:\n",
    "\n",
    "- $[ -5.99996,\\ -135.22 ]$\n",
    "\n",
    "which matches the transcript’s description: both are negative, meaning **increase** both θ₀ and θ₁ to reduce loss (since gradient descent updates subtract the gradient). [stackoverflow](https://stackoverflow.com/questions/17784587/gradient-descent-using-python-and-numpy)\n",
    "\n",
    "***\n",
    "\n",
    "### Step 5: Single‑argument gradient wrapper\n",
    "\n",
    "As with the loss, it is convenient to create a **single‑argument** gradient function that only takes θ; X and y are captured from the outer scope:\n",
    "\n",
    "```python\n",
    "def gradient_single_arg(theta):\n",
    "    return gradient_theta(X, y, theta)\n",
    "```\n",
    "\n",
    "Now you can evaluate the “2D slope” at any θ by calling:\n",
    "\n",
    "```python\n",
    "gradient_single_arg(np.array([0.0, 0.0]))\n",
    "# -> large magnitude entries (far from optimum)\n",
    "\n",
    "gradient_single_arg(np.array([0.9, 0.1]))\n",
    "# -> much smaller gradient (close to optimum)\n",
    "```\n",
    "\n",
    "The transcript notes that for θ close to the correct answer (~0.9, 0.1), the gradient components are **small**, indicating you are near a minimum. [stackoverflow](https://stackoverflow.com/questions/17784587/gradient-descent-using-python-and-numpy)\n",
    "\n",
    "***\n",
    "\n",
    "### Step 6: Reusing the same gradient descent function (1D → 2D)\n",
    "\n",
    "A crucial point in the transcript: the **same** generic gradient‑descent function used in 1D works unchanged in 2D, thanks to NumPy’s vectorization. [stackoverflow](https://stackoverflow.com/questions/17784587/gradient-descent-using-python-and-numpy)\n",
    "\n",
    "A generic gradient descent:\n",
    "\n",
    "```python\n",
    "def gradient_descent(df, theta_init, alpha, n_steps):\n",
    "    \"\"\"\n",
    "    df:  function that returns gradient given theta (shape (d,))\n",
    "    theta_init: initial parameter vector\n",
    "    alpha: learning rate\n",
    "    n_steps: number of iterations\n",
    "    \"\"\"\n",
    "    theta = theta_init.copy()\n",
    "    for step in range(n_steps):\n",
    "        grad = df(theta)          # df returns vector gradient\n",
    "        theta = theta - alpha * grad\n",
    "    return theta\n",
    "```\n",
    "\n",
    "Note:\n",
    "\n",
    "- In 1D, `theta` was a scalar, `grad` was a scalar; subtraction worked.  \n",
    "- In 2D, `theta` is a 2‑element NumPy array, `grad` is a 2‑element array; subtraction also works elementwise.  \n",
    "\n",
    "So we simply pass the new 2D gradient:\n",
    "\n",
    "```python\n",
    "theta_start = np.array([0.0, 0.0])\n",
    "alpha = 0.0001            # example learning rate\n",
    "n_steps = 100000          # many steps (the transcript notes this is slow)\n",
    "\n",
    "theta_gd = gradient_descent(gradient_single_arg, theta_start, alpha, n_steps)\n",
    "print(theta_gd)\n",
    "```\n",
    "\n",
    "- The instructor mentions not actually running it live because it takes ~30s–1min as written. [stackoverflow](https://stackoverflow.com/questions/17784587/gradient-descent-using-python-and-numpy)\n",
    "- After running, the trajectory moves from (0, 0) toward something like (0.888, 0.10), close to the optimal (0.92, 0.105). [towardsdatascience](https://towardsdatascience.com/linear-regression-and-gradient-descent-for-absolute-beginners-eef9574eadb0/)\n",
    "\n",
    "You can track the path by recording θ at each step:\n",
    "\n",
    "```python\n",
    "def gradient_descent_with_trace(df, theta_init, alpha, n_steps):\n",
    "    theta = theta_init.copy()\n",
    "    trace = [theta.copy()]\n",
    "    for step in range(n_steps):\n",
    "        grad = df(theta)\n",
    "        theta = theta - alpha * grad\n",
    "        trace.append(theta.copy())\n",
    "    return theta, np.array(trace)\n",
    "```\n",
    "\n",
    "This trace can be plotted over the 2D loss surface (contours) to visualize the “path” sliding down toward the minimum; the transcript says you will explore such visualization on homework. [mattsosna](https://mattsosna.com/LR-grad-desc/)\n",
    "\n",
    "***\n",
    "\n",
    "### Step 7: Behavior of gradient descent in 2D\n",
    "\n",
    "The transcript notes several qualitative behaviors:\n",
    "\n",
    "- Starting from θ = , both components of the gradient are negative, so the algorithm increases both θ₀ and θ₁. [stackoverflow](https://stackoverflow.com/questions/17784587/gradient-descent-using-python-and-numpy)\n",
    "- Early steps: the parameters move **quickly**, making large jumps as gradients are large. [towardsdatascience](https://towardsdatascience.com/linear-regression-and-gradient-descent-for-absolute-beginners-eef9574eadb0/)\n",
    "- As we approach the bottom of the “bowl” (the convex loss surface), gradients shrink, steps become small, and θ values approach the optimal solution. [towardsdatascience](https://towardsdatascience.com/linear-regression-and-gradient-descent-for-absolute-beginners-eef9574eadb0/)\n",
    "- With the simple implementation and chosen learning rate, the algorithm gets to about (0.888, 0.10), close but not exactly the scikit‑learn optimum, because:\n",
    "  - learning rate may be suboptimal  \n",
    "  - fixed step size  \n",
    "  - limited iterations  \n",
    "\n",
    "The instructor comments that this simple implementation is **“finicky”**: different starting points or learning rates can change convergence speed and behavior. Industrial‑strength implementations need more robust strategies (e.g., adaptive step sizes, momentum, etc.). [stackabuse](https://stackabuse.com/gradient-descent-in-python-implementation-and-theory/)\n",
    "\n",
    "***\n",
    "\n",
    "### Step 8: Big picture and why this is “cool”\n",
    "\n",
    "The transcript’s main takeaways:\n",
    "\n",
    "- You derive the gradient of the **per‑example squared error** for the 2D linear regression model using calculus and chain rule. [youtube](https://www.youtube.com/watch?v=KLXP2RL0-Vg)\n",
    "- You average across all data to get the gradient of the overall loss. [mattsosna](https://mattsosna.com/LR-grad-desc/)\n",
    "- You implement that gradient directly in Python/NumPy and plug it into a **generic** gradient descent routine previously used for 1D. [stackoverflow](https://stackoverflow.com/questions/17784587/gradient-descent-using-python-and-numpy)\n",
    "- Without relying on scikit‑learn or other libraries’ optimizers, you now numerically find near‑optimal values for both θ₀ and θ₁ for the tips dataset. [mattsosna](https://mattsosna.com/LR-grad-desc/)\n",
    "\n",
    "You’ve effectively built your own small 2D gradient descent optimizer for linear regression from first principles."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
