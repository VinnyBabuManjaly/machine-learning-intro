{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f957aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "This is a regular paragraph block. \n",
    "Professionally productize highly efficient results with world-class core competencies. \n",
    "Objectively matrix leveraged architectures vis-a-vis error-free applications. \n",
    "Completely maximize customized portals via fully researched metrics. \n",
    "Enthusiastically generate premier action items through web-enabled e-markets. \n",
    "Efficiently parallel task holistic intellectual capital and client-centric markets.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9aac79eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/vinny/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e1ce58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'a',\n",
       " 'regular',\n",
       " 'paragraph',\n",
       " 'block',\n",
       " '.',\n",
       " 'Professionally',\n",
       " 'productize',\n",
       " 'highly',\n",
       " 'efficient',\n",
       " 'results',\n",
       " 'with',\n",
       " 'world-class',\n",
       " 'core',\n",
       " 'competencies',\n",
       " '.',\n",
       " 'Objectively',\n",
       " 'matrix',\n",
       " 'leveraged',\n",
       " 'architectures',\n",
       " 'vis-a-vis',\n",
       " 'error-free',\n",
       " 'applications',\n",
       " '.',\n",
       " 'Completely',\n",
       " 'maximize',\n",
       " 'customized',\n",
       " 'portals',\n",
       " 'via',\n",
       " 'fully',\n",
       " 'researched',\n",
       " 'metrics',\n",
       " '.',\n",
       " 'Enthusiastically',\n",
       " 'generate',\n",
       " 'premier',\n",
       " 'action',\n",
       " 'items',\n",
       " 'through',\n",
       " 'web-enabled',\n",
       " 'e-markets',\n",
       " '.',\n",
       " 'Efficiently',\n",
       " 'parallel',\n",
       " 'task',\n",
       " 'holistic',\n",
       " 'intellectual',\n",
       " 'capital',\n",
       " 'and',\n",
       " 'client-centric',\n",
       " 'markets',\n",
       " '.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word Tokenizing a String\n",
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae7295a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nThis is a regular paragraph block.',\n",
       " 'Professionally productize highly efficient results with world-class core competencies.',\n",
       " 'Objectively matrix leveraged architectures vis-a-vis error-free applications.',\n",
       " 'Completely maximize customized portals via fully researched metrics.',\n",
       " 'Enthusiastically generate premier action items through web-enabled e-markets.',\n",
       " 'Efficiently parallel task holistic intellectual capital and client-centric markets.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentence Tokenization of a string\n",
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02e2a0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " 'Completely',\n",
       " 'Efficiently',\n",
       " 'Enthusiastically',\n",
       " 'Objectively',\n",
       " 'Professionally',\n",
       " 'This',\n",
       " 'a',\n",
       " 'action',\n",
       " 'and',\n",
       " 'applications',\n",
       " 'architectures',\n",
       " 'block',\n",
       " 'capital',\n",
       " 'client-centric',\n",
       " 'competencies',\n",
       " 'core',\n",
       " 'customized',\n",
       " 'e-markets',\n",
       " 'efficient',\n",
       " 'error-free',\n",
       " 'fully',\n",
       " 'generate',\n",
       " 'highly',\n",
       " 'holistic',\n",
       " 'intellectual',\n",
       " 'is',\n",
       " 'items',\n",
       " 'leveraged',\n",
       " 'markets',\n",
       " 'matrix',\n",
       " 'maximize',\n",
       " 'metrics',\n",
       " 'paragraph',\n",
       " 'parallel',\n",
       " 'portals',\n",
       " 'premier',\n",
       " 'productize',\n",
       " 'regular',\n",
       " 'researched',\n",
       " 'results',\n",
       " 'task',\n",
       " 'through',\n",
       " 'via',\n",
       " 'vis-a-vis',\n",
       " 'web-enabled',\n",
       " 'with',\n",
       " 'world-class'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique Words with `set`\n",
    "set(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59e9d259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counts of words\n",
    "len(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "947c21bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9056603773584906"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lexical Diversity\n",
    "# The lexical diversity of a text is the ratio of unique words to the total words. \n",
    "\n",
    "len(set(word_tokenize(text)))/len(word_tokenize(text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
