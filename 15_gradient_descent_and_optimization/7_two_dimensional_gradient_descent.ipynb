{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25eef8f2",
   "metadata": {},
   "source": [
    "## Two-dimensional gradient descent\n",
    "\n",
    "Two-dimensional gradient descent is the extension of 1D gradient descent to functions of multiple parameters, where the “slope” is now a vector called the gradient. \n",
    "\n",
    "In the tips example, the two parameters are the intercept (fixed tip amount) and the tip percentage, and gradient descent moves both together to minimize mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f523251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Loading tips dataset\n",
    "df = sns.load_dataset(\"tips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a82c1b",
   "metadata": {},
   "source": [
    "### From 1D to 2D linear regression\n",
    "\n",
    "In 1D, the model had a single parameter: just a tip percentage. Now the model is generalized to two parameters:\n",
    "\n",
    "- $\\theta_0$: a fixed offset (intercept), e.g., a base tip in dollars  \n",
    "- $\\theta_1$: the tip percentage\n",
    "\n",
    "So the prediction for tip is:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\theta_0 + \\theta_1 \\cdot \\text{bill}\n",
    "$$\n",
    "\n",
    "- $\\hat{y}$: predicted tip  \n",
    "- $\\text{bill}$: bill amount  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d50cc5",
   "metadata": {},
   "source": [
    "### The bias column trick (intercept as a feature)\n",
    "\n",
    "Instead of treating the intercept specially, the model can be rewritten in a unified way by adding a “bias” column:\n",
    "\n",
    "1. Start with the tips dataset containing:\n",
    "   - `bill` (feature)\n",
    "   - `tip` (target)\n",
    "\n",
    "2. Create a new dataset with:\n",
    "   - `bias` = 1 for every row  \n",
    "   - `bill` as before  \n",
    "\n",
    "So each row of the feature matrix $X$ looks like:\n",
    "\n",
    "$$\n",
    "X_i = [1,\\ \\text{bill}_i]\n",
    "$$\n",
    "\n",
    "Now model prediction becomes:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = \\theta_0 \\cdot X_{i,0} + \\theta_1 \\cdot X_{i,1}\n",
    "= \\theta_0 \\cdot 1 + \\theta_1 \\cdot \\text{bill}_i\n",
    "$$\n",
    "\n",
    "This is algebraically identical to the usual intercept + slope form, but now both parameters sit in **one** vector $\\theta = [\\theta_0,\\ \\theta_1]$, and both features are in **one** matrix $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f185e118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient and intercept are [0.10502452] 0.9202696135546731\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression(fit_intercept = True)\n",
    "X = df[[\"total_bill\"]]\n",
    "y = df[\"tip\"]\n",
    "model.fit(X, y)\n",
    "\n",
    "print(\"Coefficient and intercept are\", model.coef_, model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22c51db",
   "metadata": {},
   "source": [
    "#### Why this is useful\n",
    "\n",
    "- Conceptually cleaner: intercept is just another coefficient.  \n",
    "- Implementation-wise, gradient descent over multiple parameters becomes easier to write:\n",
    "  - predictions are $X \\theta$ (matrix–vector product)\n",
    "  - gradients, updates, etc. use the same vector/matrix operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05b8b141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python-style implementation of the setup\n",
    "\n",
    "# Add bias column\n",
    "df[\"bias\"] = 1.0\n",
    "\n",
    "# Feature matrix X and target y\n",
    "X = df[[\"bias\", \"total_bill\"]]  # shape (n_samples, 2)\n",
    "y = df[\"tip\"]            # shape (n_samples,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1bc265",
   "metadata": {},
   "source": [
    "### Predictions with a parameter vector θ\n",
    "\n",
    "Given a parameter vector:\n",
    "\n",
    "$$\n",
    "\\theta = \n",
    "\\begin{bmatrix}\n",
    "\\theta_0 \\\\\n",
    "\\theta_1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Predictions are:\n",
    "\n",
    "$$\n",
    "\\hat{y} = X @  \\theta\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "568e64fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In code:\n",
    "\n",
    "def predict(X, theta):\n",
    "    \"\"\"\n",
    "    X: shape (n_samples, 2) -> columns: bias, bill\n",
    "    theta: shape (2,) -> [theta0, theta1]\n",
    "    \"\"\"\n",
    "    return theta[0] * X.iloc[:, 0] + theta[1] * X.iloc[:, 1]\n",
    "\n",
    "# Because the bias column is all ones, \n",
    "# you could omit `X[:, 0]` and just use `theta0` directly, \n",
    "# but keeping it gives a uniform structure for all parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649ce991",
   "metadata": {},
   "source": [
    "### Mean Squared Error (MSE) loss in 2D\n",
    "\n",
    "The loss function to minimize is **mean squared error**:\n",
    "\n",
    "$$\n",
    "\\text{MSE}(\\theta) = \\frac{1}{n} \\sum_{i=1}^n \\big(\\hat{y}_i - y_i\\big)^2\n",
    "= \\frac{1}{n} \\sum_{i=1}^n \\big((\\theta_0 + \\theta_1 \\cdot \\text{bill}_i) - y_i\\big)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59f471a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(theta, X, y_obs):\n",
    "    y_hat = theta[0] * X.iloc[:, 0] + theta[1] * X.iloc[:, 1]\n",
    "    return np.mean((y_hat - y_obs) ** 2)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1be8e87",
   "metadata": {},
   "source": [
    "#### Exploring the loss with different θ\n",
    "\n",
    "- θ₀ = 1.5, θ₁ = 0.05 → some MSE  \n",
    "- θ₀ = 2.5, θ₁ = 0.05 → different MSE  \n",
    "- θ₀ = 1.5, θ₁ = 0.00 → larger MSE  \n",
    "\n",
    "This suggests there is some combination of θ₀ and θ₁ that gives the smallest possible MSE. That combination is what optimization (gradient descent or libraries) will find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6fc7b921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5340521752049179\n",
      "1.5160890604508195\n",
      "4.1514475409836065\n"
     ]
    }
   ],
   "source": [
    "# Examples in Python:\n",
    "\n",
    "theta_try = [1.5, 0.05]\n",
    "print(mse_loss(theta_try, X, y))\n",
    "\n",
    "theta_try2 = np.array([2.5, 0.05])\n",
    "print(mse_loss(theta_try2, X, y))\n",
    "\n",
    "theta_try3 = np.array([1.5, 0.0])\n",
    "print(mse_loss(theta_try3, X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacfdd0a",
   "metadata": {},
   "source": [
    "### Brute-force search in 2D\n",
    "\n",
    "Before using gradient descent, **brute forcing** is tried out: try many combinations of θ₀ and θ₁ on a grid, compute the loss for each, and pick the smallest.\n",
    "\n",
    "Conceptually:\n",
    "\n",
    "1. Choose a range of θ₀ values (e.g., from 0 to 2 dollars).\n",
    "2. Choose a range of θ₁ values (e.g., from 0 to 0.2 = 20%).\n",
    "3. Evaluate MSE at each pair (θ₀, θ₁) and record it.\n",
    "4. The best grid point approximates the true minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25ef1531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best grid theta: [0.88888889 0.11111111]\n",
      "Best grid loss: 1.046873057073467\n"
     ]
    }
   ],
   "source": [
    "theta0_values = np.linspace(0.0, 2.0, 10)   # 10 values\n",
    "theta1_values = np.linspace(0.0, 0.2, 10)   # 10 values\n",
    "\n",
    "best_loss = float(\"inf\")\n",
    "best_theta = None\n",
    "\n",
    "for t0 in theta0_values:\n",
    "    for t1 in theta1_values:\n",
    "        theta = np.array([t0, t1])\n",
    "        loss = mse_loss(theta, X, y)\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_theta = theta\n",
    "\n",
    "print(\"Best grid theta:\", best_theta)\n",
    "print(\"Best grid loss:\", best_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ebc6f6",
   "metadata": {},
   "source": [
    "This yields some approximate optimum, e.g. something like θ₀ ≈ 0.8888, θ₁ ≈ 0.111, close to but not exactly the library’s 0.92 and 0.105, because the grid is coarse (only 10×10 points).\n",
    "\n",
    "Brute force is conceptually easy but:\n",
    "\n",
    "- Expensive: cost grows rapidly with dimension and grid resolution.  \n",
    "- Inexact: you only hit the grid points, not the true continuous minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ff86823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "type": "surface",
         "x": [
          [
           0,
           0.2222222222222222,
           0.4444444444444444,
           0.6666666666666666,
           0.8888888888888888,
           1.1111111111111112,
           1.3333333333333333,
           1.5555555555555554,
           1.7777777777777777,
           2
          ],
          [
           0,
           0.2222222222222222,
           0.4444444444444444,
           0.6666666666666666,
           0.8888888888888888,
           1.1111111111111112,
           1.3333333333333333,
           1.5555555555555554,
           1.7777777777777777,
           2
          ],
          [
           0,
           0.2222222222222222,
           0.4444444444444444,
           0.6666666666666666,
           0.8888888888888888,
           1.1111111111111112,
           1.3333333333333333,
           1.5555555555555554,
           1.7777777777777777,
           2
          ],
          [
           0,
           0.2222222222222222,
           0.4444444444444444,
           0.6666666666666666,
           0.8888888888888888,
           1.1111111111111112,
           1.3333333333333333,
           1.5555555555555554,
           1.7777777777777777,
           2
          ],
          [
           0,
           0.2222222222222222,
           0.4444444444444444,
           0.6666666666666666,
           0.8888888888888888,
           1.1111111111111112,
           1.3333333333333333,
           1.5555555555555554,
           1.7777777777777777,
           2
          ],
          [
           0,
           0.2222222222222222,
           0.4444444444444444,
           0.6666666666666666,
           0.8888888888888888,
           1.1111111111111112,
           1.3333333333333333,
           1.5555555555555554,
           1.7777777777777777,
           2
          ],
          [
           0,
           0.2222222222222222,
           0.4444444444444444,
           0.6666666666666666,
           0.8888888888888888,
           1.1111111111111112,
           1.3333333333333333,
           1.5555555555555554,
           1.7777777777777777,
           2
          ],
          [
           0,
           0.2222222222222222,
           0.4444444444444444,
           0.6666666666666666,
           0.8888888888888888,
           1.1111111111111112,
           1.3333333333333333,
           1.5555555555555554,
           1.7777777777777777,
           2
          ],
          [
           0,
           0.2222222222222222,
           0.4444444444444444,
           0.6666666666666666,
           0.8888888888888888,
           1.1111111111111112,
           1.3333333333333333,
           1.5555555555555554,
           1.7777777777777777,
           2
          ],
          [
           0,
           0.2222222222222222,
           0.4444444444444444,
           0.6666666666666666,
           0.8888888888888888,
           1.1111111111111112,
           1.3333333333333333,
           1.5555555555555554,
           1.7777777777777777,
           2
          ]
         ],
         "y": [
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0.022222222222222223,
           0.022222222222222223,
           0.022222222222222223,
           0.022222222222222223,
           0.022222222222222223,
           0.022222222222222223,
           0.022222222222222223,
           0.022222222222222223,
           0.022222222222222223,
           0.022222222222222223
          ],
          [
           0.044444444444444446,
           0.044444444444444446,
           0.044444444444444446,
           0.044444444444444446,
           0.044444444444444446,
           0.044444444444444446,
           0.044444444444444446,
           0.044444444444444446,
           0.044444444444444446,
           0.044444444444444446
          ],
          [
           0.06666666666666667,
           0.06666666666666667,
           0.06666666666666667,
           0.06666666666666667,
           0.06666666666666667,
           0.06666666666666667,
           0.06666666666666667,
           0.06666666666666667,
           0.06666666666666667,
           0.06666666666666667
          ],
          [
           0.08888888888888889,
           0.08888888888888889,
           0.08888888888888889,
           0.08888888888888889,
           0.08888888888888889,
           0.08888888888888889,
           0.08888888888888889,
           0.08888888888888889,
           0.08888888888888889,
           0.08888888888888889
          ],
          [
           0.11111111111111112,
           0.11111111111111112,
           0.11111111111111112,
           0.11111111111111112,
           0.11111111111111112,
           0.11111111111111112,
           0.11111111111111112,
           0.11111111111111112,
           0.11111111111111112,
           0.11111111111111112
          ],
          [
           0.13333333333333333,
           0.13333333333333333,
           0.13333333333333333,
           0.13333333333333333,
           0.13333333333333333,
           0.13333333333333333,
           0.13333333333333333,
           0.13333333333333333,
           0.13333333333333333,
           0.13333333333333333
          ],
          [
           0.15555555555555556,
           0.15555555555555556,
           0.15555555555555556,
           0.15555555555555556,
           0.15555555555555556,
           0.15555555555555556,
           0.15555555555555556,
           0.15555555555555556,
           0.15555555555555556,
           0.15555555555555556
          ],
          [
           0.17777777777777778,
           0.17777777777777778,
           0.17777777777777778,
           0.17777777777777778,
           0.17777777777777778,
           0.17777777777777778,
           0.17777777777777778,
           0.17777777777777778,
           0.17777777777777778,
           0.17777777777777778
          ],
          [
           0.2,
           0.2,
           0.2,
           0.2,
           0.2,
           0.2,
           0.2,
           0.2,
           0.2,
           0.2
          ]
         ],
         "z": [
          [
           10.896283606557375,
           9.61309801659583,
           8.428677858733051,
           7.3430231329690345,
           6.3561338393037845,
           5.4680099777373,
           4.678651548269581,
           3.988058550900628,
           3.3962309856304396,
           2.9031688524590162
          ],
          [
           8.123556369763206,
           7.035787497065371,
           6.046784056466302,
           5.156546047965999,
           4.365073471564461,
           3.6723663272616873,
           3.0784246150576804,
           2.5832483349524393,
           2.1868374869459624,
           1.8891920710382517
          ],
          [
           5.815433238615665,
           4.923081083181542,
           4.129494359846185,
           3.434673068609593,
           2.838617209471767,
           2.3413267824327058,
           1.9428017874924104,
           1.6430422246508807,
           1.442048093908116,
           1.3398193952641166
          ],
          [
           3.9719142131147542,
           3.2749787749443433,
           2.6768087688726983,
           2.177404194899818,
           1.7767650530257035,
           1.474891343250354,
           1.2717830655737705,
           1.1674402199959524,
           1.1618628065168994,
           1.255050825136612
          ],
          [
           2.592999293260474,
           2.0914805723537744,
           1.6887272835458407,
           1.384739426836673,
           1.1795170022262702,
           1.0730600097146326,
           1.0653684493017608,
           1.1564423209876544,
           1.346281624772313,
           1.6348863606557378
          ],
          [
           1.678688479052823,
           1.372586475409836,
           1.1652499038656143,
           1.056678764420158,
           1.046873057073467,
           1.1358327818255416,
           1.3235579386763814,
           1.6100485276259866,
           1.9953045486743575,
           2.479326001821494
          ],
          [
           1.2289817704918033,
           1.118296484112528,
           1.1063766298320177,
           1.1932222076502732,
           1.378833217567294,
           1.66320965958308,
           2.046351533697632,
           2.5282588399109494,
           3.108931578223032,
           3.7883697486338797
          ],
          [
           1.2438791675774135,
           1.32861059846185,
           1.5121074614450516,
           1.7943697565270191,
           2.175397483707751,
           2.65519064298725,
           3.2337492343655123,
           3.9110732578425416,
           4.687162713418336,
           5.562017601092896
          ],
          [
           1.7233806703096541,
           2.0035288184578026,
           2.3824423987047156,
           2.8601214110503954,
           3.4365658554948397,
           4.1117757320380495,
           4.885751040680025,
           5.758491781420764,
           6.729997954260271,
           7.8002695591985445
          ],
          [
           2.667486278688525,
           3.1430511441003843,
           3.717381441611011,
           4.390477171220401,
           5.162338332928559,
           6.032964926735478,
           7.002356952641167,
           8.070514410645618,
           9.237437300748836,
           10.50312562295082
          ]
         ]
        },
        {
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "Optimal Point",
         "type": "scatter3d",
         "x": [
          0.8888888888888888
         ],
         "y": [
          0.11111111111111112
         ],
         "z": [
          1.046873057073467
         ]
        }
       ],
       "layout": {
        "scene": {
         "xaxis": {
          "title": {
           "text": "theta0"
          }
         },
         "yaxis": {
          "title": {
           "text": "theta1"
          }
         },
         "zaxis": {
          "title": {
           "text": "MSE"
          }
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "uvalues = np.linspace(0, 2, 10)\n",
    "vvalues = np.linspace(0, 0.2, 10)\n",
    "(u,v) = np.meshgrid(uvalues, vvalues)\n",
    "thetas = np.vstack((u.flatten(),v.flatten()))\n",
    "\n",
    "MSE = np.array([mse_loss(t, X, y) for t in thetas.T])\n",
    "\n",
    "loss_surface = go.Surface(x=u, y=v, z=np.reshape(MSE, u.shape))\n",
    "\n",
    "ind = np.argmin(MSE)\n",
    "optimal_point = go.Scatter3d(name = \"Optimal Point\",\n",
    "    x = [thetas.T[ind,0]], y = [thetas.T[ind,1]], \n",
    "    z = [MSE[ind]],\n",
    "    marker=dict(size=10, color=\"red\"))\n",
    "\n",
    "fig = go.Figure(data=[loss_surface, optimal_point])\n",
    "fig.update_layout(scene = dict(\n",
    "    xaxis_title = \"theta0\",\n",
    "    yaxis_title = \"theta1\",\n",
    "    zaxis_title = \"MSE\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4c71d9",
   "metadata": {},
   "source": [
    "### Using optimization libraries (2D)\n",
    "\n",
    "The next step is to use a general optimization routine (e.g. from SciPy or similar) that performs gradient-based optimization.\n",
    "\n",
    "To use such a routine, it’s convenient to have a **single-argument** loss function: one that only accepts θ, with X and y captured from the surrounding scope:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "746e12a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized theta: [0.92027035 0.10502448]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  message: Optimization terminated successfully.\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: 1.0360194420114932\n",
       "        x: [ 9.203e-01  1.050e-01]\n",
       "      nit: 3\n",
       "      jac: [-4.470e-08 -2.980e-08]\n",
       " hess_inv: [[ 2.980e+00 -1.253e-01]\n",
       "            [-1.253e-01  6.335e-03]]\n",
       "     nfev: 15\n",
       "     njev: 5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Wrapper that “freezes” X and y\n",
    "def mse_loss_single_arg(theta):\n",
    "    return mse_loss(theta, X, y)\n",
    "\n",
    "# Then you can call an optimizer given a starting guess, e.g. θ = [0.0, 0.0]:\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "theta_init = np.array([0.0, 0.0])\n",
    "\n",
    "result = minimize(mse_loss_single_arg, theta_init)\n",
    "theta_opt = result.x\n",
    "\n",
    "print(\"Optimized theta:\", theta_opt)  # should be close to [0.92, 0.105]\n",
    "result\n",
    "\n",
    "# This replicates what scikit-learn did internally: it minimized the MSE loss over θ₀ and θ₁ using gradient-based methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99079f43",
   "metadata": {},
   "source": [
    "### Intuition for multi-dimensional gradient descent\n",
    "\n",
    "In 1D, the slope at a point tells you the best direction (up or down) to move. In 2D:\n",
    "\n",
    "- The function $f(\\theta_0, \\theta_1)$ defines a surface.  \n",
    "- At any point on that surface, the “steepest way down” is no longer just left or right; it is a **direction in the 2D plane** of parameters.  \n",
    "- That direction is encoded in the **gradient vector**.\n",
    "\n",
    "Imagine a 3D surface:\n",
    "\n",
    "- Horizontal axes: θ₀ and θ₁  \n",
    "- Vertical axis: loss value  \n",
    "\n",
    "At a current position (θ₀, θ₁), the gradient arrow points in the direction of **steepest increase** of the function. For gradient descent, we step in the **opposite** direction (negative gradient) to go downhill.\n",
    "\n",
    "As we repeat this process:\n",
    "\n",
    "1. Compute gradient at current θ.  \n",
    "2. Take a step against the gradient, scaled by a learning rate α.  \n",
    "3. The path curves around as the gradient direction changes.  \n",
    "4. Stop when the loss stops decreasing significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70521c24",
   "metadata": {},
   "source": [
    "### The gradient: definition and example\n",
    "\n",
    "For a 2D function $f(\\theta_0, \\theta_1)$, the gradient is:\n",
    "\n",
    "$$\n",
    "\\nabla_{\\theta} f =\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial f}{\\partial \\theta_0} \\\\\n",
    "\\frac{\\partial f}{\\partial \\theta_1}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "For example:\n",
    "\n",
    "$$\n",
    "f(\\theta_0, \\theta_1)\n",
    "= 8 \\theta_0^2 + 3 \\theta_0 \\theta_1\n",
    "$$\n",
    "\n",
    "This is **not** a regression loss; it’s just a random 2D function used to demonstrate partial derivatives.\n",
    "\n",
    "Compute partial derivatives:\n",
    "\n",
    "1. Partial derivative w.r.t. $\\theta_0$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial \\theta_0}\n",
    "= 16 \\theta_0 + 3 \\theta_1\n",
    "$$\n",
    "\n",
    "2. Partial derivative w.r.t. $\\theta_1$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial \\theta_1}\n",
    "= 3 \\theta_0\n",
    "$$\n",
    "\n",
    "So the gradient is:\n",
    "\n",
    "$$\n",
    "\\nabla_{\\theta} f(\\theta_0, \\theta_1)\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "16 \\theta_0 + 3 \\theta_1 \\\\\n",
    "3 \\theta_0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This is exactly the column-vector to be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f78257",
   "metadata": {},
   "source": [
    "#### Interpreting gradient components\n",
    "\n",
    "- Top entry: “If I nudge θ₀ up a tiny amount, how much does f go up or down?”  \n",
    "- Bottom entry: “If I nudge θ₁ up a tiny amount, how much does f go up or down?”\n",
    "\n",
    "In optimization:\n",
    "\n",
    "- If a component of the gradient is **positive**, increasing that θ increases the function (bad for minimization), so we should decrease that θ.  \n",
    "- If a component is **negative**, increasing that θ decreases the function (good), so we should increase that θ.\n",
    "\n",
    "In gradient descent, all of this is unified into:\n",
    "\n",
    "$$\n",
    "\\theta^{(t+1)} = \\theta^{(t)} - \\alpha \\nabla_{\\theta} f(\\theta^{(t)})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785c4cc3",
   "metadata": {},
   "source": [
    "### Generalizing to p dimensions\n",
    "\n",
    "For a function of $p+1$ parameters $\\theta_0, \\theta_1, \\dots, \\theta_p$:\n",
    "\n",
    "$$\n",
    "\\nabla_{\\theta} f(\\theta) =\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial f}{\\partial \\theta_0} \\\\\n",
    "\\frac{\\partial f}{\\partial \\theta_1} \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{\\partial f}{\\partial \\theta_p}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- Each row corresponds to “what happens to the loss if I slightly increase this particular θ_j, holding the others fixed”.  \n",
    "- Together, these partials form the vector that points in steepest ascent.  \n",
    "\n",
    "Gradient descent moves in the **negative** of this vector, scaled by a learning rate α."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a31fe90",
   "metadata": {},
   "source": [
    "### Multidimensional gradient descent update rule\n",
    "\n",
    "The updated rule:\n",
    "\n",
    "$$\n",
    "\\theta^{(t+1)}\n",
    "=\n",
    "\\theta^{(t)} - \\alpha \\nabla_{\\theta} L(\\theta^{(t)}, X, y)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $L(\\theta, X, y)$: loss function (e.g., MSE)  \n",
    "- $\\theta^{(t)}$: current parameter vector at step t  \n",
    "- $\\theta^{(t+1)}$: next parameter vector  \n",
    "- $\\alpha$: learning rate  \n",
    "- $\\nabla_{\\theta} L$: gradient of loss w.r.t. θ\n",
    "\n",
    "You must also choose a **starting guess**, e.g.:\n",
    "\n",
    "- All zeros: θ = [0, 0, …]  \n",
    "- Small random numbers  \n",
    "- Some heuristic or prior-based guess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87217025",
   "metadata": {},
   "source": [
    "### Gradient for 2D linear regression MSE (explicit)\n",
    "\n",
    "For completeness, here is the gradient of the MSE for linear regression in matrix form.\n",
    "\n",
    "Loss:\n",
    "\n",
    "$$\n",
    "L(\\theta) = \\frac{1}{n} \\sum_{i=1}^n (\\hat{y}_i - y_i)^2\n",
    "= \\frac{1}{n} \\| X\\theta - y \\|^2\n",
    "$$\n",
    "\n",
    "The gradient is:\n",
    "\n",
    "$$\n",
    "\\nabla_{\\theta} L(\\theta)\n",
    "=\n",
    "\\frac{2}{n} X^\\top (X\\theta - y)\n",
    "$$\n",
    "\n",
    "For our 2D case (bias + bill), this gives a 2D gradient vector:\n",
    "\n",
    "- First component: derivative w.r.t. θ₀  \n",
    "- Second component: derivative w.r.t. θ₁  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feca67c6",
   "metadata": {},
   "source": [
    "### Python implementation: 2D gradient descent for tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1044af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss_and_grad(theta, X, y):\n",
    "    \"\"\"\n",
    "    Returns both loss and gradient for efficiency.\n",
    "\n",
    "    theta: (2,)\n",
    "    X:     (n,2)\n",
    "    y:     (n,)\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    y_pred = X @ theta           # shape (n,)\n",
    "    errors = y_pred - y          # shape (n,)\n",
    "    loss = np.mean(errors ** 2)\n",
    "    grad = (2 / n) * (X.T @ errors)  # shape (2,)\n",
    "    return loss, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ec0d2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient descent theta: bias         NaN\n",
      "total_bill   NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def gradient_descent(X, y, alpha=0.01, n_steps=1000):\n",
    "    theta = np.zeros(X.shape[1])  # start at [0.0, 0.0]\n",
    "    history = []\n",
    "\n",
    "    for step in range(n_steps):\n",
    "        loss, grad = mse_loss_and_grad(theta, X, y)\n",
    "        theta = theta - alpha * grad\n",
    "        history.append(loss)\n",
    "        # Optional early stopping if loss change is tiny\n",
    "        if step > 0 and abs(history[-2] - history[-1]) < 1e-8:\n",
    "            break\n",
    "\n",
    "    return theta, history\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "theta_gd, loss_history = gradient_descent(X, y, alpha=0.01, n_steps=5000)\n",
    "print(\"Gradient descent theta:\", theta_gd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f0a813",
   "metadata": {},
   "source": [
    "- This procedure will converge to parameters close to what the library found (~0.92 and ~0.105) if α and step count are chosen reasonably.  \n",
    "- The path of θ through parameter space is the 2D analogue of sliding down a 1D curve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aea696",
   "metadata": {},
   "source": [
    "### Summary of key ideas\n",
    "\n",
    "- Two-parameter model: tip prediction is $ \\theta_0 + \\theta_1 \\cdot \\text{bill} $.  \n",
    "- Bias column trick: add a column of ones so intercept and slope can be handled uniformly via matrix operations.  \n",
    "- MSE loss: measures how far predictions are from actual tips, averaged over all examples.  \n",
    "- Brute-force optimization: try a grid of θ values and pick the one with smallest loss, but this is coarse and inefficient.  \n",
    "- Optimization libraries: can minimize a single-argument loss function (θ → loss) and recover optimal θ automatically.  \n",
    "- Gradient in multiple dimensions: vector of partial derivatives; each component tells how the function changes with respect to that parameter.  \n",
    "- Gradient descent in $p$ dimensions: repeatedly update θ by subtracting a scaled gradient until the loss stops decreasing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
